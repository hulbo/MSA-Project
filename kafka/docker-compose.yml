networks:
  kafka_default:
    driver: bridge

services:
  zookeeper:
    image: wurstmeister/zookeeper
    container_name: zookeeper
    networks:
      - kafka_default
    ports:
      - "2181:2181"

  kafka:
    image: wurstmeister/kafka
    container_name: kafka
    networks:
      - kafka_default
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      # --- 이 부분이 중요합니다 ---
      # KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      # KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,INTERNAL://0.0.0.0:29092 # 컨테이너 내부 리스너 정의 (EXTERNAL은 명시적으로 PLAINTEXT로)
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,INTERNAL://kafka:29092 # 외부 광고 주소와 내부 광고 주소
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,INTERNAL:PLAINTEXT # 리스너별 보안 프로토콜
      # --- 여기까지 변경 ---
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock

  kafka-connect:
    image: confluentinc/cp-kafka-connect:latest
    container_name: kafka-connect
    networks:
      - kafka_default
    depends_on:
      - kafka
    ports:
      - "8083:8083"
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8083"]
      interval: 10s
      timeout: 5s
      retries: 5
    environment:
      CONNECT_BOOTSTRAP_SERVERS: 'kafka:29092' # 내부 통신용 주소 (INTERNAL 리스너)
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: "connect-cluster"
      CONNECT_CONFIG_STORAGE_TOPIC: "connect-configs"
      CONNECT_OFFSET_STORAGE_TOPIC: "connect-offsets"
      CONNECT_STATUS_STORAGE_TOPIC: "connect-status"
      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "true"  # 변경: 스키마 활성화
      CONNECT_VALUE_CONVERTER_FORMAT: "timestamp-millis"
      CONNECT_PLUGIN_PATH: "/usr/share/java,/etc/kafka-connect/plugins,/usr/share/confluent-hub-components"
      CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect"
      CONNECT_RETRY_BACKOFF_MS: "5000"
      CONNECT_REQUEST_TIMEOUT_MS: "20000"
      CONNECT_LOG_LEVEL: "INFO"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      errors.retry.timeout: "300000"
      errors.retry.delay: "5000"
      errors.deadletterqueue.topic.name: "failed-records"
      # DB 연결정보를 환경변수로 넘김 (docker-compose 실행 시 OS 환경변수 필요)
      CONNECT_CONFIG_PROVIDERS: env
      CONNECT_CONFIG_PROVIDERS_ENV_CLASS: org.apache.kafka.common.config.provider.EnvVarConfigProvider
      CONNECT_FILE_CONFIG_PATH: "/etc/kafka-connect/configs/secrets.properties"  # 설정파일
      MARIA_DB_URL: ${OCI_MARIA_DB_URL}
      MARIA_DB_USER: ${OCI_MARIA_DB_USER}
      MARIA_DB_PASSWORD: ${OCI_MARIA_DB_PASSWORD}
      ORACLE_DB_URL: ${OCI_ORACLE_DB_URL}
      ORACLE_DB_USER: ${OCI_ORACLE_DB_ID}
      ORACLE_DB_PASSWORD: ${OCI_ORACLE_DB_PASSWORD}
    volumes:
      - ./kafka-connectors/jdbc:/etc/kafka-connect/plugins/jdbc
      - ./config:/etc/kafka-connect/configs

  kafka-init:
    image: wurstmeister/kafka
    container_name: kafka-init
    networks:
      - kafka_default
    depends_on:
      - kafka
    entrypoint: ["/bin/sh", "-c"]
    command: |
      "
      # kafka가 완전히 올라오도록 잠시 대기 후 토픽 생성
      sleep 10;
      
      # 메시지를 60초 동안만 유지하고 자동 삭제
      # 메시지를 소비한 후 즉시 삭제 (큐처럼 동작)
      # 로그 파일 크기를 1MB로 설정하여 삭제 속도 최적화
      # 't_sc_orders' 토픽 생성 쓰기
      # kafka-topics.sh --create --topic write_topic_maria_t_sc_orders --bootstrap-server kafka:9092 --partitions 3 --replication-factor 1
      # 내부포트로 변경
      kafka-topics.sh --create --topic write_topic_maria_t_sc_orders --bootstrap-server kafka:29092 --partitions 3 --replication-factor 1
      "

  kafka-connect-init:
    image: curlimages/curl
    container_name: kafka-connect-init
    networks:
      - kafka_default
    depends_on:
      kafka-connect:
        condition: service_healthy
    volumes:
      - ./config:/config
    entrypoint: ["/bin/sh", "-c"]

    command: |
      "
      sleep 10;
      curl -X POST -H \"Content-Type: application/json\" --data @/config/jdbc-sink-orders.json http://kafka-connect:8083/connectors;
      curl -X POST -H \"Content-Type: application/json\" --data @/config/jdbc-connectors-orders.json http://kafka-connect:8083/connectors;
      curl -X POST -H \"Content-Type: application/json\" --data @/config/jdbc-connectors-users.json http://kafka-connect:8083/connectors;
      "

  zipkin:
    image: openzipkin/zipkin
    container_name: zipkin
    networks:
      - kafka_default
    ports:
      - "9411:9411"
    environment:
      - STORAGE_TYPE=mem # 기본적으로 메모리 저장소 사용
    depends_on:
      - kafka # Kafka가 먼저 실행된 후 Zipkin 실행

volumes:
  kafka_data:
